{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d724807",
   "metadata": {},
   "source": [
    "Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fcddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, rnn_type='LSTM',\n",
    "                 dropout=0.2, bidirectional=False,use_attention=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.is_bidirectional = bidirectional\n",
    "        self.rnn_type = rnn_type\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        rnn_cls = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[rnn_type]\n",
    "        self.rnn = rnn_cls(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim // self.num_directions,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        if self.use_attention:\n",
    "            return outputs,hidden\n",
    "        else:\n",
    "            return hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, rnn_type='LSTM',\n",
    "                 dropout=0.2,use_attention=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn_type = rnn_type\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        rnn_cls = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[rnn_type]\n",
    "        self.rnn = rnn_cls(\n",
    "            input_size=embed_dim + hidden_dim if use_attention else embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.attn = None\n",
    "        if use_attention:\n",
    "            self.attn = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_dim, 1)\n",
    "            )\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_token, hidden_state, encoder_outputs=None,src_mask=None):\n",
    "        embedded = self.embedding(input_token.unsqueeze(1))  # (B, 1, E)\n",
    "\n",
    "        if self.use_attention and encoder_outputs is not None:\n",
    "            # encoder_outputs: (B, T, H), hidden_state[0][-1]: (B, H)\n",
    "            if self.rnn_type == 'LSTM':\n",
    "                query = hidden_state[0][-1].unsqueeze(1)  # (B, 1, H)\n",
    "            else:\n",
    "                query = hidden_state[-1].unsqueeze(1)\n",
    "\n",
    "            # Repeat query across time steps\n",
    "            query = query.expand(-1, encoder_outputs.size(1), -1)  # (B, T, H)\n",
    "\n",
    "            # Concatenate and compute attention weights\n",
    "            energy = self.attn(torch.cat((encoder_outputs, query), dim=2))  # (B, T, 1)\n",
    "            energy = energy.squeeze(2)\n",
    "            if src_mask is not None:\n",
    "                energy = energy.masked_fill(~src_mask, float('-inf'))\n",
    "            attn_weights = F.softmax(energy, dim=1)  # (B, T)\n",
    "\n",
    "            # Compute context vector\n",
    "            context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)  # (B, 1, H)\n",
    "            rnn_input = torch.cat((embedded, context), dim=2)  # (B, 1, E + H)\n",
    "        else:\n",
    "            rnn_input = embedded\n",
    "\n",
    "        rnn_output, hidden = self.rnn(rnn_input, hidden_state)  # rnn_output: (B, 1, H)\n",
    "        logits = self.fc_out(rnn_output.squeeze(1))  # (B, V)\n",
    "        if self.use_attention:\n",
    "            return logits, hidden, attn_weights  # Return attention weights\n",
    "        else:\n",
    "            return logits, hidden\n",
    "        \n",
    "\n",
    "class TransliterationModel(nn.Module):\n",
    "    def __init__(self, input_vocab_size, output_vocab_size, embed_dim, hidden_dim,\n",
    "                 enc_layers, dec_layers, rnn_type='LSTM', dropout=0.2, bidirectional=False,use_attention=False):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_vocab_size, embed_dim, hidden_dim,\n",
    "                                    enc_layers, rnn_type, dropout, bidirectional,use_attention)\n",
    "        self.decoder = Decoder(output_vocab_size, embed_dim, hidden_dim,\n",
    "                                     dec_layers, rnn_type, dropout,use_attention)\n",
    "        self.rnn_type = rnn_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        vocab_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size, device=src.device)\n",
    "        src_mask = (src != 0)\n",
    "        if self.use_attention:\n",
    "            enc_outputs, enc_hidden = self.encoder(src)\n",
    "        else:\n",
    "            enc_hidden = self.encoder(src)\n",
    "\n",
    "        def merge_bidir_states(state):\n",
    "            return torch.cat([state[::2], state[1::2]], dim=2)\n",
    "\n",
    "        def pad_layers(state, target_layers):\n",
    "            if state.size(0) == target_layers:\n",
    "                return state\n",
    "            pad = torch.zeros(target_layers - state.size(0), *state.shape[1:], device=state.device)\n",
    "            return torch.cat([state, pad], dim=0)\n",
    "\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            h, c = enc_hidden\n",
    "            if self.bidirectional:\n",
    "                h, c = merge_bidir_states(h), merge_bidir_states(c)\n",
    "            h, c = pad_layers(h, self.dec_layers), pad_layers(c, self.dec_layers)\n",
    "            dec_hidden = (h, c)\n",
    "        else:\n",
    "            h = enc_hidden\n",
    "            if self.bidirectional:\n",
    "                h = merge_bidir_states(h)\n",
    "            h = pad_layers(h, self.dec_layers)\n",
    "            dec_hidden = h\n",
    "\n",
    "        dec_input = tgt[:, 0]  # Start token\n",
    "        for t in range(1, tgt_len):\n",
    "            if self.use_attention:\n",
    "                output, dec_hidden, attn_weights = self.decoder(dec_input, dec_hidden, enc_outputs, src_mask)\n",
    "                if t == 1:  # Only collect attention weights for visualization once\n",
    "                    all_attn_weights = attn_weights.unsqueeze(1)  # (B, 1, src_len)\n",
    "                else:\n",
    "                    all_attn_weights = torch.cat((all_attn_weights, attn_weights.unsqueeze(1)), dim=1)\n",
    "            else:\n",
    "                output, dec_hidden = self.decoder(dec_input, dec_hidden)\n",
    "\n",
    "            outputs[:, t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            dec_input = tgt[:, t] if teacher_force else top1\n",
    "\n",
    "        if self.use_attention:\n",
    "            return outputs, all_attn_weights  # Shape: (B, tgt_len-1, src_len)\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "def read_pairs(file_path):\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        return [(line.split('\\t')[1], line.split('\\t')[0]) for line in f.read().strip().split('\\n') if '\\t' in line]\n",
    "\n",
    "def build_vocab_and_prepare_batch(seqs, device):\n",
    "    special_tokens = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
    "    \n",
    "    # Build character sets\n",
    "    unique_chars_latin = sorted(set(ch for seq in seqs for ch in seq[0]))\n",
    "    unique_chars_dev = sorted(set(ch for seq in seqs for ch in seq[1]))\n",
    "\n",
    "    # Build vocabularies\n",
    "    src_vocab = {ch: idx + len(special_tokens) for idx, ch in enumerate(unique_chars_latin)}\n",
    "    tgt_vocab = {ch: idx + len(special_tokens) for idx, ch in enumerate(unique_chars_dev)}\n",
    "    src_vocab.update(special_tokens)\n",
    "    tgt_vocab.update(special_tokens)\n",
    "\n",
    "    idx2src = {idx: ch for ch, idx in src_vocab.items()}\n",
    "    idx2tgt = {idx: ch for ch, idx in tgt_vocab.items()}\n",
    "\n",
    "    def encode_text(seq, vocab):\n",
    "        return [vocab.get(ch, vocab['<unk>']) for ch in seq]\n",
    "\n",
    "    def create_batch(pairs):\n",
    "        src = [torch.tensor(encode_text(x, src_vocab) + [src_vocab['<eos>']]) for x, _ in pairs]\n",
    "        tgt = [torch.tensor([tgt_vocab['<sos>']] + encode_text(y, tgt_vocab) + [tgt_vocab['<eos>']]) for _, y in pairs]\n",
    "        src = pad_sequence(src, batch_first=True, padding_value=src_vocab['<pad>'])\n",
    "        tgt = pad_sequence(tgt, batch_first=True, padding_value=tgt_vocab['<pad>'])\n",
    "        return src.to(device), tgt.to(device)\n",
    "\n",
    "    return src_vocab, idx2src, tgt_vocab, idx2tgt, create_batch, unique_chars_latin, unique_chars_dev\n",
    "\n",
    "def compute_word_level_accuracy(preds, targets, vocab):\n",
    "    sos, eos, pad = vocab['<sos>'], vocab['<eos>'], vocab['<pad>']\n",
    "    preds = preds.tolist()\n",
    "    targets = targets.tolist()\n",
    "    correct = 0\n",
    "    for p, t in zip(preds, targets):\n",
    "        p = [x for x in p if x != pad and x != eos]\n",
    "        t = [x for x in t if x != pad and x != eos]\n",
    "        if p == t:\n",
    "            correct += 1\n",
    "    return correct / len(preds) * 100\n",
    "\n",
    "def run_training():\n",
    "    # Initialize wandb config\n",
    "    wandb.init()\n",
    "    cfg = wandb.config\n",
    "    wandb.run.name = (\n",
    "    f\"es_{cfg.embedding_size}_hs_{cfg.hidden_size}_\"\n",
    "    f\"enc_{cfg.enc_layers}_dec_{cfg.dec_layers}_\"\n",
    "    f\"rnn_{cfg.rnn_type}_dropout_{cfg.dropout_rate}_\"\n",
    "    f\"bidirectional_{cfg.is_bidirectional}_\"\n",
    "    f\"lr_{cfg.learning_rate}_bs_{cfg.batch_size}_\"\n",
    "    f\"epochs_{cfg.epochs}_tfp_{cfg.teacher_forcing_prob}_\"\n",
    "    f\"beam_size_{cfg.beam_size}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
    "    dev_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
    "    train_set = read_pairs(train_path)\n",
    "    dev_set = read_pairs(dev_path)\n",
    "\n",
    "    src_vocab, idx2src, tgt_vocab, idx2tgt, create_batch, _, _ = build_vocab_and_prepare_batch(train_set, device)\n",
    "\n",
    "    # Initialize model, optimizer, criterion\n",
    "    model = TransliterationModel(\n",
    "        len(src_vocab), len(tgt_vocab), cfg.embedding_size, cfg.hidden_size,\n",
    "        cfg.enc_layers, cfg.dec_layers, cfg.rnn_type, cfg.dropout_rate,\n",
    "        cfg.is_bidirectional,cfg.use_attention\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        total_loss, total_acc = 0, 0\n",
    "        random.shuffle(train_set)\n",
    "\n",
    "        for i in range(0, len(train_set), cfg.batch_size):\n",
    "            batch = train_set[i:i+cfg.batch_size]\n",
    "            src, tgt = create_batch(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if cfg.use_attention:\n",
    "                outputs, attn_weights = model(src, tgt, cfg.teacher_forcing_prob)\n",
    "            else:\n",
    "                outputs = model(src, tgt, cfg.teacher_forcing_prob)\n",
    "\n",
    "            loss = criterion(outputs[:, 1:].reshape(-1, outputs.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = outputs.argmax(-1)\n",
    "            acc = compute_word_level_accuracy(preds[:, 1:], tgt[:, 1:], tgt_vocab)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "\n",
    "        avg_train_loss = total_loss / (len(train_set) // cfg.batch_size)\n",
    "        avg_train_acc = total_acc / (len(train_set) // cfg.batch_size)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        dev_loss, dev_acc = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(dev_set), cfg.batch_size):\n",
    "                batch = dev_set[i:i+cfg.batch_size]\n",
    "                src, tgt = create_batch(batch)\n",
    "                if cfg.use_attention:\n",
    "                    outputs, attn_weights = model(src, tgt, 0)\n",
    "                else:\n",
    "                    outputs = model(src, tgt, 0,)\n",
    "                loss = criterion(outputs[:, 1:].reshape(-1, outputs.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "\n",
    "                preds = outputs.argmax(-1)\n",
    "                acc = compute_word_level_accuracy(preds[:, 1:], tgt[:, 1:], tgt_vocab)\n",
    "\n",
    "                dev_loss += loss.item()\n",
    "                dev_acc += acc\n",
    "\n",
    "        avg_dev_loss = dev_loss / (len(dev_set) // cfg.batch_size)\n",
    "        avg_dev_acc = dev_acc / (len(dev_set) // cfg.batch_size)\n",
    "\n",
    "        # Logging\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": avg_train_loss,\n",
    "            \"Train Accuracy\": avg_train_acc,\n",
    "            \"Validation Loss\": avg_dev_loss,\n",
    "            \"Validation Accuracy\": avg_dev_acc,\n",
    "        })\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{cfg.epochs} | Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.2f}% | Val Loss: {avg_dev_loss:.4f}, Val Acc: {avg_dev_acc:.2f}%\")\n",
    "\n",
    "    wandb.finish()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7647825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(cfg,model_path,project_name,csv_file_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    wandb.finish()\n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        name = 'best_model_test_eval',\n",
    "        resume=\"never\",\n",
    "        reinit=True,\n",
    "        config=cfg\n",
    "    )\n",
    "    # Load and prepare data\n",
    "    train_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
    "    train_set = read_pairs(train_path)\n",
    "    test_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n",
    "    test_set = read_pairs(test_path)\n",
    "\n",
    "    src_vocab, idx2src, tgt_vocab, idx2tgt, create_batch, _, _ = build_vocab_and_prepare_batch(train_set, device)\n",
    "\n",
    "    # Initialize model, optimizer, criterion\n",
    "    model = TransliterationModel(\n",
    "        len(src_vocab), len(tgt_vocab), cfg['embedding_size'], cfg['hidden_size'],\n",
    "        cfg['enc_layers'], cfg['dec_layers'], cfg['rnn_type'], cfg['dropout_rate'],\n",
    "        cfg['is_bidirectional'],cfg['use_attention']\n",
    "    ).to(device)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"‚ùå No saved model found, starting training.\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])\n",
    "        best_acc = 0.0\n",
    "        # Training loop\n",
    "        for epoch in range(cfg['epochs']):\n",
    "            model.train()\n",
    "            total_loss, total_acc = 0, 0\n",
    "            random.shuffle(train_set)\n",
    "\n",
    "            for i in range(0, len(train_set), cfg['batch_size']):\n",
    "                batch = train_set[i:i+cfg['batch_size']]\n",
    "                src, tgt = create_batch(batch)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                if cfg['use_attention']:\n",
    "                    outputs, attn_weights = model(src, tgt, cfg['teacher_forcing_prob'])\n",
    "                else:\n",
    "                    outputs = model(src, tgt, cfg['teacher_forcing_prob'])\n",
    "\n",
    "                loss = criterion(outputs[:, 1:].reshape(-1, outputs.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = outputs.argmax(-1)\n",
    "                acc = compute_word_level_accuracy(preds[:, 1:], tgt[:, 1:], tgt_vocab)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_acc += acc\n",
    "\n",
    "            avg_train_loss = total_loss / (len(train_set) // cfg['batch_size'])\n",
    "            avg_train_acc = total_acc / (len(train_set) // cfg['batch_size'])\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{cfg['epochs']} | Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.2f}%\")\n",
    "            wandb.log({\"Train Loss\": avg_train_loss, \"Train Accuracy\": avg_train_acc})\n",
    "\n",
    "            # Save the best model\n",
    "            if avg_train_acc > best_acc:\n",
    "                best_acc = avg_train_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"üíæ Saved new best model at epoch {epoch + 1} with accuracy {best_acc:.2f}%\")\n",
    "        print(f\"Best model saved with accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "    #test the model\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(\"‚úÖ Loaded saved model from disk.\")\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_set), cfg['batch_size']):\n",
    "            batch = test_set[i:i + cfg['batch_size']]\n",
    "            src, tgt = create_batch(batch)\n",
    "            if cfg['use_attention']:\n",
    "                outputs, attn_weights = model(src, tgt, 0)\n",
    "            else:\n",
    "                outputs = model(src, tgt, 0)\n",
    "            preds = outputs.argmax(-1)\n",
    "\n",
    "            for j in range(src.size(0)):\n",
    "                input_seq = ''.join([idx2src.get(idx.item(), '') for idx in src[j] if idx.item() not in [src_vocab['<pad>'], src_vocab['<eos>']]])\n",
    "                target_seq = ''.join([idx2tgt.get(idx.item(), '') for idx in tgt[j][1:] if idx.item() not in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]])\n",
    "                pred_seq = ''.join([idx2tgt.get(idx.item(), '') for idx in preds[j][1:] if idx.item() not in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]])\n",
    "                is_correct = target_seq == pred_seq\n",
    "                predictions.append({'Input': input_seq, 'Target': target_seq, 'Predicted': pred_seq , 'Is_Correct': \"True‚úÖ\" if is_correct else \"False‚ùå\"})\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    overall_acc = (predictions.Is_Correct == \"True‚úÖ\").mean()\n",
    "    wandb.log({\"Test Accuracy\": overall_acc})\n",
    "    table = wandb.Table(dataframe=predictions)\n",
    "    wandb.log({f\"{csv_file_name}_table\": table})\n",
    "    # finish run\n",
    "    wandb.finish()\n",
    "    predictions.to_csv(f'{csv_file_name}.csv', index=False)\n",
    "    print(f\"Saved {len(predictions)} rows, eval accuracy = {overall_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b434fa",
   "metadata": {},
   "source": [
    "Vanilla model parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30477f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {'name': 'Validation Accuracy', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'embedding_size': {'values': [128, 256]},\n",
    "        'hidden_size': {'values': [128, 256]},\n",
    "        'enc_layers': {'values': [2, 3]},\n",
    "        'dec_layers': {'values': [2, 3]},\n",
    "        'rnn_type': {'values': ['GRU', 'LSTM','RNN']},\n",
    "        'dropout_rate': {'values': [0.2, 0.3]},\n",
    "        'batch_size': {'values': [32, 64]},\n",
    "        'epochs': {\n",
    "            'values': [5, 10]},\n",
    "        'is_bidirectional': {'values': [False, True]},\n",
    "        'learning_rate': {'values': [0.001, 0.0001]},\n",
    "        'optimizer': {'values': ['adam', 'nadam']},\n",
    "        'teacher_forcing_prob': {'values': [0.2, 0.5, 0.7]},\n",
    "        'beam_size': {'values': [1,3,5]},\n",
    "        'use_attention': {'values': [False]},\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"dakshina_transliteration\")\n",
    "wandb.agent(sweep_id, function=run_training, count=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6384248",
   "metadata": {},
   "source": [
    "Vanilla model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'embedding_size':256,\n",
    "        'hidden_size': 256,\n",
    "        'enc_layers': 3,\n",
    "        'dec_layers': 3,\n",
    "        'rnn_type': 'GRU',\n",
    "        'dropout_rate': 0.3,\n",
    "        'batch_size': 64,\n",
    "        'epochs':10,\n",
    "        'is_bidirectional':False,\n",
    "        'learning_rate': 0.001,\n",
    "        'optimizer': 'nadam',\n",
    "        'teacher_forcing_prob':0.7,\n",
    "        'beam_size': 5,\n",
    "        'use_attention': False,\n",
    "    }\n",
    "model_eval(parameters,\"best_vanilla_model.pt\",\"transliteration_evaluation\",\"predictions_vanilla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd3070",
   "metadata": {},
   "source": [
    "Attention Model parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {'name': 'Validation Accuracy', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'embedding_size': {'values': [128, 256]},\n",
    "        'hidden_size': {'values': [128, 256]},\n",
    "        'enc_layers': {'values': [2, 3]},\n",
    "        'dec_layers': {'values': [2, 3]},\n",
    "        'rnn_type': {'values': ['GRU', 'LSTM','RNN']},\n",
    "        'dropout_rate': {'values': [0.2, 0.3]},\n",
    "        'batch_size': {'values': [32, 64]},\n",
    "        'epochs': {\n",
    "            'values': [5, 10]},\n",
    "        'is_bidirectional': {'values': [False, True]},\n",
    "        'learning_rate': {'values': [0.001, 0.0001]},\n",
    "        'optimizer': {'values': ['adam', 'nadam']},\n",
    "        'teacher_forcing_prob': {'values': [0.2, 0.5, 0.7]},\n",
    "        'beam_size': {'values': [1,3,5]},\n",
    "        'use_attention': {'values': [True]},\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"dakshina_transliteration_attention\")\n",
    "wandb.agent(sweep_id, function=run_training, count=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b9940",
   "metadata": {},
   "source": [
    "Attention model parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d43d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'embedding_size':256,\n",
    "        'hidden_size': 256,\n",
    "        'enc_layers': 2,\n",
    "        'dec_layers': 3,\n",
    "        'rnn_type': 'LSTM',\n",
    "        'dropout_rate': 0.3,\n",
    "        'batch_size': 64,\n",
    "        'epochs':10,\n",
    "        'is_bidirectional':True,\n",
    "        'learning_rate': 0.001,\n",
    "        'optimizer': 'adam',\n",
    "        'teacher_forcing_prob':0.7,\n",
    "        'beam_size': 3,\n",
    "        'use_attention': True,\n",
    "    }\n",
    "model_eval(parameters,\"best_attention_model.pt\",\"transliteration_attention_evaluation\",\"predictions_attention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0ee34",
   "metadata": {},
   "source": [
    "Comparing attention model with vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "wandb.init(\n",
    "    project=\"Comparison_vanilla_attention\",\n",
    "    name = 'Compare_attention_vanilla',\n",
    "    resume=\"never\",\n",
    "    reinit=True,\n",
    ")\n",
    "vanilla_predictions = pd.read_csv(\"predictions_vanilla.csv\")\n",
    "attention_predictions = pd.read_csv(\"predictions_attention.csv\")\n",
    "comparison_df = vanilla_predictions.copy()\n",
    "comparison_df['Vanilla_prediction'] = comparison_df['Predicted']\n",
    "comparison_df['Attention_prediction'] = attention_predictions['Predicted']\n",
    "comparison_df['Attention_Is_Correct'] = attention_predictions['Is_Correct']\n",
    "filtered_df = comparison_df[\n",
    "    (comparison_df['Is_Correct'] == \"False‚ùå\") &\n",
    "    (comparison_df['Attention_Is_Correct'] == \"True‚úÖ\")\n",
    "][['Input', 'Target', 'Vanilla_prediction', 'Attention_prediction']]\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "filtered_df.to_csv(\"comparison.csv\", index=False)\n",
    "table = wandb.Table(dataframe=filtered_df)\n",
    "wandb.log({\"Comparison_table\": table})\n",
    "# finish run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"comparison.csv\")\n",
    "\n",
    "# Find corrected cases\n",
    "corrected_cases = df[\n",
    "    (df[\"Vanilla_prediction\"] != df[\"Target\"]) &\n",
    "    (df[\"Attention_prediction\"] == df[\"Target\"])\n",
    "]\n",
    "\n",
    "# Character-level differences\n",
    "char_diffs = []\n",
    "for _, row in corrected_cases.iterrows():\n",
    "    vanilla = row[\"Vanilla_prediction\"]\n",
    "    correct = row[\"Target\"]\n",
    "    for v_char, c_char in zip(vanilla, correct):\n",
    "        if v_char != c_char:\n",
    "            char_diffs.append((v_char, c_char))\n",
    "\n",
    "# Count top 15\n",
    "from collections import Counter\n",
    "most_common_corrections = Counter(char_diffs).most_common(15)\n",
    "labels = [f\"{v}‚Üí{c}\" for v, c in dict(most_common_corrections).keys()]\n",
    "counts = list(dict(most_common_corrections).values())\n",
    "\n",
    "# ‚úÖ Use font from local file\n",
    "font_path = r\"font\\NotoSansDevanagari-Regular.ttf\"\n",
    "devanagari_font = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# Plot with explicit font\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=labels, y=counts, palette=\"mako\")\n",
    "\n",
    "plt.title(\"Most Common Character-Level Corrections\", fontproperties=devanagari_font)\n",
    "plt.xlabel(\"Character Correction\", fontproperties=devanagari_font)\n",
    "plt.ylabel(\"Frequency\", fontproperties=devanagari_font)\n",
    "plt.xticks(rotation=45, fontproperties=devanagari_font)\n",
    "plt.yticks(fontproperties=devanagari_font)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76303119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "import wandb\n",
    "\n",
    "# Assumes TransliterationModel, build_vocab_and_prepare_batch, compute_word_level_accuracy, and read_pairs are defined elsewhere\n",
    "\n",
    "def plot_attention(attn_weights, input_tokens, output_tokens, input_word, output_word, idx):\n",
    "    # Load Devanagari-compatible font\n",
    "    font_path = r\"font\\NotoSansDevanagari-Regular.ttf\"\n",
    "    devanagari_font = fm.FontProperties(fname=font_path, size=12)  # Increase font size here\n",
    "\n",
    "    # Define special tokens to exclude\n",
    "    special_tokens = {'<pad>', '<sos>', '<eos>'}\n",
    "    filtered_input_tokens = [tok for tok in input_tokens if tok not in special_tokens]\n",
    "    filtered_output_tokens = [tok for tok in output_tokens if tok not in special_tokens]\n",
    "    attn_weights_filtered = attn_weights[:len(filtered_output_tokens), :len(filtered_input_tokens)]\n",
    "\n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(8, 6))  # Slightly larger figure\n",
    "    ax = sns.heatmap(attn_weights_filtered,\n",
    "                     xticklabels=filtered_input_tokens,\n",
    "                     yticklabels=filtered_output_tokens,\n",
    "                     cmap='viridis',\n",
    "                     cbar_kws={\"shrink\": 0.7})\n",
    "\n",
    "    # Set font sizes for labels and title\n",
    "    ax.set_xlabel(\"Input Sequence (characters)\", fontsize=16)\n",
    "    ax.set_ylabel(\"Predicted Output (characters)\", fontproperties=devanagari_font, fontsize=16)\n",
    "    ax.set_title(f\"Heatmap {idx}: '{input_word}' - '{output_word}'\", fontproperties=devanagari_font, fontsize=16)\n",
    "\n",
    "    # Set tick label font sizes\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    # Apply Devanagari font to y-tick labels\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(devanagari_font)\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Convert to wandb.Image\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf)\n",
    "\n",
    "    return wandb.Image(image, caption=f\"{idx}: {input_word} ‚Üí {output_word}\")\n",
    "\n",
    "\n",
    "\n",
    "def attention_heatmaps(cfg, model_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    wandb.finish()\n",
    "    wandb.init(\n",
    "        project=\"transliteration_attention_heatmap\",\n",
    "        name='best_attention_model_test_eval',\n",
    "        resume=\"never\",\n",
    "        reinit=True,\n",
    "        config=cfg\n",
    "    )\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
    "    train_set = read_pairs(train_path)\n",
    "    test_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n",
    "    test_set = read_pairs(test_path)\n",
    "\n",
    "    src_vocab, idx2src, tgt_vocab, idx2tgt, create_batch, _, _ = build_vocab_and_prepare_batch(train_set, device)\n",
    "\n",
    "    # Initialize model\n",
    "    model = TransliterationModel(\n",
    "        len(src_vocab), len(tgt_vocab), cfg['embedding_size'], cfg['hidden_size'],\n",
    "        cfg['enc_layers'], cfg['dec_layers'], cfg['rnn_type'], cfg['dropout_rate'],\n",
    "        cfg['is_bidirectional'], cfg['use_attention']\n",
    "    ).to(device)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"‚ùå No saved model found, starting training.\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(cfg['epochs']):\n",
    "            model.train()\n",
    "            total_loss, total_acc = 0, 0\n",
    "            random.shuffle(train_set)\n",
    "\n",
    "            for i in range(0, len(train_set), cfg['batch_size']):\n",
    "                batch = train_set[i:i + cfg['batch_size']]\n",
    "                src, tgt = create_batch(batch)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs, attn_weights = model(src, tgt, cfg['teacher_forcing_prob'])\n",
    "\n",
    "                loss = criterion(outputs[:, 1:].reshape(-1, outputs.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = outputs.argmax(-1)\n",
    "                acc = compute_word_level_accuracy(preds[:, 1:], tgt[:, 1:], tgt_vocab)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_acc += acc\n",
    "\n",
    "            avg_train_loss = total_loss / (len(train_set) // cfg['batch_size'])\n",
    "            avg_train_acc = total_acc / (len(train_set) // cfg['batch_size'])\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{cfg['epochs']} | Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.2f}%\")\n",
    "\n",
    "            if avg_train_acc > best_acc:\n",
    "                best_acc = avg_train_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"üíæ Saved new best model at epoch {epoch + 1} with accuracy {best_acc:.2f}%\")\n",
    "\n",
    "        print(f\"Best model saved with accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(\"‚úÖ Loaded saved model from disk.\")\n",
    "    model.eval()\n",
    "\n",
    "    num_plots = 0\n",
    "    max_plots = 10\n",
    "    images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_set), cfg['batch_size']):\n",
    "            batch = test_set[i:i + cfg['batch_size']]\n",
    "            src, tgt = create_batch(batch)\n",
    "\n",
    "            outputs, attn_weights = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "            preds = outputs.argmax(-1)\n",
    "\n",
    "            for j in range(src.size(0)):\n",
    "                input_seq = ''.join([idx2src.get(idx.item(), '') for idx in src[j] if idx.item() not in [src_vocab['<pad>'], src_vocab['<eos>']]])\n",
    "                target_seq = ''.join([idx2tgt.get(idx.item(), '') for idx in tgt[j][1:] if idx.item() not in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]])\n",
    "                pred_seq = ''.join([idx2tgt.get(idx.item(), '') for idx in preds[j][1:] if idx.item() not in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]])\n",
    "\n",
    "                if num_plots < max_plots:\n",
    "                    input_tokens = [idx2src.get(idx.item(), '') for idx in src[j] if idx.item() not in [src_vocab['<pad>'], src_vocab['<eos>']]]\n",
    "                    output_tokens = [idx2tgt.get(idx.item(), '') for idx in preds[j][1:] if idx.item() not in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]]\n",
    "                    attn_matrix = attn_weights[j].cpu().numpy()\n",
    "\n",
    "                    wandb_img = plot_attention(attn_matrix, input_tokens, output_tokens, input_seq, pred_seq, num_plots + 1)\n",
    "                    images.append(wandb_img)\n",
    "                    num_plots += 1\n",
    "\n",
    "                if num_plots >= max_plots:\n",
    "                    break\n",
    "            if num_plots >= max_plots:\n",
    "                break\n",
    "\n",
    "    if images:\n",
    "        wandb.log({\"attention_heatmaps\": images})\n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e575b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'embedding_size':256,\n",
    "        'hidden_size': 256,\n",
    "        'enc_layers': 2,\n",
    "        'dec_layers': 3,\n",
    "        'rnn_type': 'LSTM',\n",
    "        'dropout_rate': 0.3,\n",
    "        'batch_size': 64,\n",
    "        'epochs':10,\n",
    "        'is_bidirectional':True,\n",
    "        'learning_rate': 0.001,\n",
    "        'optimizer': 'adam',\n",
    "        'teacher_forcing_prob':0.7,\n",
    "        'beam_size': 3,\n",
    "        'use_attention': True,\n",
    "    }\n",
    "attention_heatmaps(parameters,\"best_attention_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb046c",
   "metadata": {},
   "source": [
    "Interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fb4cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_html(words_data):\n",
    "    \"\"\"\n",
    "    words_data is a list of dictionaries, one per word.\n",
    "    Each dictionary should have:\n",
    "      - 'input_chars': list of input characters (Latin)\n",
    "      - 'output_chars': list of output characters (native script)\n",
    "      - 'attention_weights': list of lists (each inner list the attention weights for corresponding output character)\n",
    "    \"\"\"\n",
    "    html_template = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "      <meta charset=\"UTF-8\">\n",
    "      <style>\n",
    "        body {{\n",
    "          font-family: Arial, sans-serif;\n",
    "          padding: 20px;\n",
    "        }}\n",
    "        .top-attn-boxes {{\n",
    "          display: flex;\n",
    "          gap: 20px;\n",
    "          margin-bottom: 20px;\n",
    "        }}\n",
    "        .attn-box {{\n",
    "          border: 1px solid #ccc;\n",
    "          padding: 10px;\n",
    "          width: 150px;\n",
    "          height: 50px;\n",
    "          text-align: center;\n",
    "          font-size: 18px;\n",
    "          background-color: #f9f9f9;\n",
    "          border-radius: 8px;\n",
    "          display: flex;\n",
    "          align-items: center;\n",
    "          justify-content: center;\n",
    "        }}\n",
    "        .sentence {{\n",
    "          line-height: 2;\n",
    "          font-size: 28px;\n",
    "        }}\n",
    "        .word {{\n",
    "          margin-right: 20px; /* proper spacing between words */\n",
    "          display: inline-block;\n",
    "        }}\n",
    "        .output-char {{\n",
    "          display: inline-block;\n",
    "          margin: 0 3px;\n",
    "          padding: 8px 5px;\n",
    "          cursor: pointer;\n",
    "          border-bottom: 1px dotted #555;\n",
    "          transition: background-color 0.2s;\n",
    "        }}\n",
    "        .output-char:hover {{\n",
    "          background-color: #eef;\n",
    "        }}\n",
    "      </style>\n",
    "    </head>\n",
    "    <body>\n",
    "      <div class=\"top-attn-boxes\">\n",
    "        <div class=\"attn-box\" id=\"top1\">‚Äî</div>\n",
    "        <div class=\"attn-box\" id=\"top2\">‚Äî</div>\n",
    "        <div class=\"attn-box\" id=\"top3\">‚Äî</div>\n",
    "      </div>\n",
    "      <div class=\"sentence\">\n",
    "    \"\"\"\n",
    "    # For each word in the sentence\n",
    "    for word in words_data:\n",
    "        input_chars = word[\"input_chars\"]\n",
    "        output_chars = word[\"output_chars\"]\n",
    "        attention_weights = word[\"attention_weights\"]\n",
    "        word_html = '<span class=\"word\">'\n",
    "        for i, out_char in enumerate(output_chars):\n",
    "            # Prepare data: list of dicts with char and weight for this output char.\n",
    "            data = [\n",
    "                {\"char\": input_chars[j], \"weight\": round(w, 3)}\n",
    "                for j, w in enumerate(attention_weights[i])\n",
    "            ]\n",
    "            # Encode the data into a HTML-friendly format.\n",
    "            data_str = str(data).replace(\"'\", \"&quot;\")\n",
    "            # If an output character is empty, we show a placeholder (like ‚ê£)\n",
    "            display_char = out_char if out_char else \"‚ê£\"\n",
    "            word_html += f'<span class=\"output-char\" data-attn=\"{data_str}\">{display_char}</span>'\n",
    "        word_html += '</span>'  # Close the word span.\n",
    "        html_template += word_html\n",
    "\n",
    "    html_template += \"\"\"\n",
    "      </div>\n",
    "      <script>\n",
    "        function showTop3(attnData) {\n",
    "          // Create a shallow copy to sort so we don't modify the original array\n",
    "          let sortedData = attnData.slice().sort((a, b) => b.weight - a.weight);\n",
    "          const top = sortedData.slice(0, 3);\n",
    "          for (let i = 0; i < 3; i++) {\n",
    "            const el = document.getElementById(\"top\" + (i + 1));\n",
    "            if (i < top.length) {\n",
    "              el.innerText = top[i].char + \" : \" + top[i].weight.toFixed(2);\n",
    "            } else {\n",
    "              el.innerText = \"‚Äî\";\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "\n",
    "        // Attach hover event to each character.\n",
    "        document.querySelectorAll(\".output-char\").forEach(span => {\n",
    "          span.addEventListener(\"mouseenter\", () => {\n",
    "            // Replace HTML entity quotes with actual quotes and parse the JSON data.\n",
    "            const attn = JSON.parse(span.dataset.attn.replace(/&quot;/g, '\"'));\n",
    "            showTop3(attn);\n",
    "          });\n",
    "        });\n",
    "      </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec8e94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "def Interactive_plot(cfg, model_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    wandb.finish()\n",
    "    wandb.init(\n",
    "        project=\"transliteration_attention_Interactive_plot\",\n",
    "        name='connectivity_plot',\n",
    "        resume=\"never\",\n",
    "        reinit=True,\n",
    "        config=cfg\n",
    "    )\n",
    "\n",
    "    # Load training and test datasets\n",
    "    train_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
    "    train_set = read_pairs(train_path)\n",
    "    test_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n",
    "    test_set = read_pairs(test_path)\n",
    "\n",
    "    # Prepare vocabulary and batch creation\n",
    "    src_vocab, idx2src, tgt_vocab, idx2tgt, create_batch, tensor_to_words, _ = build_vocab_and_prepare_batch(train_set, device)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = TransliterationModel(\n",
    "        len(src_vocab), len(tgt_vocab), cfg['embedding_size'], cfg['hidden_size'],\n",
    "        cfg['enc_layers'], cfg['dec_layers'], cfg['rnn_type'], cfg['dropout_rate'],\n",
    "        cfg['is_bidirectional'], cfg['use_attention']\n",
    "    ).to(device)\n",
    "\n",
    "    # If model not trained yet, train it\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"‚ùå No saved model found, starting training.\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(cfg['epochs']):\n",
    "            model.train()\n",
    "            total_loss, total_acc = 0, 0\n",
    "            random.shuffle(train_set)\n",
    "\n",
    "            for i in range(0, len(train_set), cfg['batch_size']):\n",
    "                batch = train_set[i:i + cfg['batch_size']]\n",
    "                src, tgt = create_batch(batch)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs, attn_weights = model(src, tgt, cfg['teacher_forcing_prob'])\n",
    "\n",
    "                loss = criterion(outputs[:, 1:].reshape(-1, outputs.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = outputs.argmax(-1)\n",
    "                acc = compute_word_level_accuracy(preds[:, 1:], tgt[:, 1:], tgt_vocab)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_acc += acc\n",
    "\n",
    "            avg_train_loss = total_loss / (len(train_set) // cfg['batch_size'])\n",
    "            avg_train_acc = total_acc / (len(train_set) // cfg['batch_size'])\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{cfg['epochs']} | Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.2f}%\")\n",
    "\n",
    "            if avg_train_acc > best_acc:\n",
    "                best_acc = avg_train_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"üíæ Saved new best model at epoch {epoch + 1} with accuracy {best_acc:.2f}%\")\n",
    "\n",
    "        print(f\"Best model saved with accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "    # Load and evaluate saved model\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(\"‚úÖ Loaded saved model from disk.\")\n",
    "\n",
    "    model.eval()\n",
    "    num_plots = 0\n",
    "    max_plots = 10\n",
    "    word_data=[]\n",
    "    random.shuffle(test_set)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_set), cfg['batch_size']):\n",
    "            batch = test_set[i:i + cfg['batch_size']]\n",
    "            src, tgt = create_batch(batch)\n",
    "\n",
    "            outputs, attn_weights = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "            preds = outputs.argmax(-1)\n",
    "\n",
    "            for j in range(src.size(0)):\n",
    "                input_seq = ''.join([idx2src.get(idx.item(), '') for idx in src[j] if idx.item() not in [src_vocab['<pad>'], src_vocab['<eos>']]])\n",
    "                target_seq = ''.join([idx2tgt.get(idx.item(), '') for idx in tgt[j][1:] if idx.item() not in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]])\n",
    "                pred_seq = ''.join([idx2tgt.get(idx.item(), '') for idx in preds[j][1:] if idx.item() not in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]])\n",
    "\n",
    "                if num_plots < max_plots:\n",
    "                    input_tokens = [idx2src.get(idx.item(), '') for idx in src[j] if idx.item() not in [src_vocab['<pad>'], src_vocab['<eos>']]]\n",
    "                    output_tokens = [idx2tgt.get(idx.item(), '') for idx in preds[j][1:] if idx.item() not in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]]\n",
    "                    attn_matrix = attn_weights[j].cpu().numpy()\n",
    "                        # Define special tokens to exclude\n",
    "                    special_tokens = {'<pad>', '<sos>', '<eos>'}\n",
    "                    filtered_input_tokens = [tok for tok in input_tokens if tok not in special_tokens]\n",
    "                    filtered_output_tokens = [tok for tok in output_tokens if tok not in special_tokens]\n",
    "                    attn_matrix_filtered = attn_matrix[:len(filtered_output_tokens), :len(filtered_input_tokens)]\n",
    "                    num_plots += 1\n",
    "                    pred_dict = {\n",
    "                        \"input_chars\": filtered_input_tokens,\n",
    "                        \"output_chars\": filtered_output_tokens,\n",
    "                        \"attention_weights\": attn_matrix_filtered.tolist(),\n",
    "                    }\n",
    "                    word_data.append(pred_dict)\n",
    "                else:\n",
    "                    break\n",
    "            if num_plots >= max_plots:\n",
    "                break\n",
    "    # Generate HTML\n",
    "    html_str = generate_sentence_html(word_data)\n",
    "\n",
    "    # Save the HTML file with UTF-8 encoding\n",
    "    with open(\"sentence_attention.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "\n",
    "    wandb.log({\"sentence_attention_viz\": wandb.Html(\"sentence_attention.html\", inject=False)})\n",
    "    wandb.finish()\n",
    "\n",
    "    print(\"HTML file generated and logged to wandb (if wandb is configured).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39edba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\code\\DL\\da6401_assignment3\\wandb\\run-20250520_045349-k89kx8e8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot/runs/k89kx8e8' target=\"_blank\">connectivity_plot</a></strong> to <a href='https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot' target=\"_blank\">https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot/runs/k89kx8e8' target=\"_blank\">https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot/runs/k89kx8e8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded saved model from disk.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">connectivity_plot</strong> at: <a href='https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot/runs/k89kx8e8' target=\"_blank\">https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot/runs/k89kx8e8</a><br> View project at: <a href='https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot' target=\"_blank\">https://wandb.ai/harshtrivs-indian-institute-of-technology-madras/transliteration_attention_Interactive_plot</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_045349-k89kx8e8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file generated and logged to wandb (if wandb is configured).\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "        'embedding_size':256,\n",
    "        'hidden_size': 256,\n",
    "        'enc_layers': 2,\n",
    "        'dec_layers': 3,\n",
    "        'rnn_type': 'LSTM',\n",
    "        'dropout_rate': 0.3,\n",
    "        'batch_size': 64,\n",
    "        'epochs':10,\n",
    "        'is_bidirectional':True,\n",
    "        'learning_rate': 0.001,\n",
    "        'optimizer': 'adam',\n",
    "        'teacher_forcing_prob':0.7,\n",
    "        'beam_size': 3,\n",
    "        'use_attention': True,\n",
    "    }\n",
    "Interactive_plot(parameters,\"best_attention_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
